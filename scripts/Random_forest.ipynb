{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b300c466-df2f-45c3-b9ed-37fdf646289c",
   "metadata": {},
   "source": [
    "# Random Forest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8fa4665f-92bd-4fe7-9ac3-5c0ecda718f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import sys\n",
    "import math\n",
    "\n",
    "import pickle\n",
    "import optuna\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "# from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import cross_val_predict\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import mean_squared_error, auc, roc_curve\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "data_folder = '../data/'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "885999c3-8449-492e-b9d6-1cf1f51167f1",
   "metadata": {},
   "source": [
    "### A) Load the dataset and convert categorical features to a suitable numerical representation (use dummy-variable encoding). \n",
    "- Split the data into a training set (80%) and a test set (20%). Pair each feature vector with the corresponding label, i.e., whether the outcome_type is adoption or not. \n",
    "- Standardize the values of each feature in the data to have mean 0 and variance 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2b5ddfbb-2734-47d7-abf2-b06c96c17073",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LU4</th>\n",
       "      <th>LC4</th>\n",
       "      <th>LU3</th>\n",
       "      <th>LC3</th>\n",
       "      <th>LU2</th>\n",
       "      <th>LC2</th>\n",
       "      <th>LU1</th>\n",
       "      <th>LC1</th>\n",
       "      <th>nbr1_LU3</th>\n",
       "      <th>nbr1_LC3</th>\n",
       "      <th>...</th>\n",
       "      <th>nbr7_LU2</th>\n",
       "      <th>nbr7_LC2</th>\n",
       "      <th>nbr7_LU1</th>\n",
       "      <th>nbr7_LC1</th>\n",
       "      <th>nbr8_LU3</th>\n",
       "      <th>nbr8_LC3</th>\n",
       "      <th>nbr8_LU2</th>\n",
       "      <th>nbr8_LC2</th>\n",
       "      <th>nbr8_LU1</th>\n",
       "      <th>nbr8_LC1</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RELI</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48561099</th>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>...</td>\n",
       "      <td>LU221</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU221</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48611112</th>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>...</td>\n",
       "      <td>LU221</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU221</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU221</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU221</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU221</td>\n",
       "      <td>LC21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48621113</th>\n",
       "      <td>LU103</td>\n",
       "      <td>LC47</td>\n",
       "      <td>LU103</td>\n",
       "      <td>LC47</td>\n",
       "      <td>LU421</td>\n",
       "      <td>LC31</td>\n",
       "      <td>LU421</td>\n",
       "      <td>LC31</td>\n",
       "      <td>LU106</td>\n",
       "      <td>LC12</td>\n",
       "      <td>...</td>\n",
       "      <td>LU222</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU222</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48621114</th>\n",
       "      <td>LU106</td>\n",
       "      <td>LC12</td>\n",
       "      <td>LU106</td>\n",
       "      <td>LC12</td>\n",
       "      <td>LU106</td>\n",
       "      <td>LC12</td>\n",
       "      <td>LU106</td>\n",
       "      <td>LC12</td>\n",
       "      <td>LU142</td>\n",
       "      <td>LC15</td>\n",
       "      <td>...</td>\n",
       "      <td>LU222</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU222</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48621115</th>\n",
       "      <td>LU142</td>\n",
       "      <td>LC11</td>\n",
       "      <td>LU142</td>\n",
       "      <td>LC15</td>\n",
       "      <td>LU142</td>\n",
       "      <td>LC15</td>\n",
       "      <td>LU142</td>\n",
       "      <td>LC15</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>...</td>\n",
       "      <td>LU222</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU222</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 56 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LU4   LC4    LU3   LC3    LU2   LC2    LU1   LC1 nbr1_LU3  \\\n",
       "RELI                                                                    \n",
       "48561099  LU301  LC41  LU301  LC41  LU301  LC41  LU301  LC41    LU301   \n",
       "48611112  LU402  LC61  LU402  LC61  LU402  LC61  LU402  LC61    LU402   \n",
       "48621113  LU103  LC47  LU103  LC47  LU421  LC31  LU421  LC31    LU106   \n",
       "48621114  LU106  LC12  LU106  LC12  LU106  LC12  LU106  LC12    LU142   \n",
       "48621115  LU142  LC11  LU142  LC15  LU142  LC15  LU142  LC15    LU402   \n",
       "\n",
       "         nbr1_LC3  ... nbr7_LU2 nbr7_LC2 nbr7_LU1 nbr7_LC1 nbr8_LU3 nbr8_LC3  \\\n",
       "RELI               ...                                                         \n",
       "48561099     LC41  ...    LU221     LC21    LU221     LC21    LU301     LC41   \n",
       "48611112     LC61  ...    LU221     LC21    LU221     LC21    LU221     LC21   \n",
       "48621113     LC12  ...    LU222     LC21    LU222     LC21    LU402     LC61   \n",
       "48621114     LC15  ...    LU222     LC21    LU222     LC21    LU402     LC61   \n",
       "48621115     LC61  ...    LU222     LC21    LU222     LC21    LU402     LC61   \n",
       "\n",
       "         nbr8_LU2 nbr8_LC2 nbr8_LU1 nbr8_LC1  \n",
       "RELI                                          \n",
       "48561099    LU301     LC41    LU301     LC41  \n",
       "48611112    LU221     LC21    LU221     LC21  \n",
       "48621113    LU402     LC61    LU402     LC61  \n",
       "48621114    LU402     LC61    LU402     LC61  \n",
       "48621115    LU402     LC61    LU402     LC61  \n",
       "\n",
       "[5 rows x 56 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "columns = ['LU4', 'LC4', 'LU3', 'LC3', 'LU2', 'LC2', 'LU1', 'LC1', 'nbr1_LU3', 'nbr1_LC3', 'nbr1_LU2', 'nbr1_LC2', 'nbr1_LU1',\n",
    "           'nbr1_LC1', 'nbr2_LU3', 'nbr2_LC3', 'nbr2_LU2', 'nbr2_LC2', 'nbr2_LU1', 'nbr2_LC1', 'nbr3_LU3', 'nbr3_LC3',\n",
    "           'nbr3_LU2', 'nbr3_LC2', 'nbr3_LU1', 'nbr3_LC1', 'nbr4_LU3', 'nbr4_LC3', 'nbr4_LU2', 'nbr4_LC2', 'nbr4_LU1',\n",
    "           'nbr4_LC1', 'nbr5_LU3', 'nbr5_LC3', 'nbr5_LU2', 'nbr5_LC2', 'nbr5_LU1', 'nbr5_LC1', 'nbr6_LU3', 'nbr6_LC3',\n",
    "           'nbr6_LU2', 'nbr6_LC2', 'nbr6_LU1', 'nbr6_LC1', 'nbr7_LU3', 'nbr7_LC3', 'nbr7_LU2', 'nbr7_LC2', 'nbr7_LU1',\n",
    "           'nbr7_LC1', 'nbr8_LU3', 'nbr8_LC3', 'nbr8_LU2', 'nbr8_LC2', 'nbr8_LU1', 'nbr8_LC1']\n",
    "\n",
    "original_data = pd.read_csv(os.path.join(data_folder, 'trainset_with_neighbour.csv'), index_col=0)\n",
    "original_data = original_data[columns]\n",
    "original_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "de21f3d7-0304-4c88-92b6-7c481595ef6e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The length of the data with all rows is : 348474\n",
      "The length of the data without the rows with nan value is: 348474\n"
     ]
    }
   ],
   "source": [
    "print('The length of the data with all rows is : {}'.format(len(original_data)))\n",
    "original_data.dropna(inplace=True)\n",
    "print('The length of the data without the rows with nan value is: {}'.format(len(original_data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9d3ee6ab-6d69-460a-bf54-7616a65327ec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LU4</th>\n",
       "      <th>LC4</th>\n",
       "      <th>LU3</th>\n",
       "      <th>LC3</th>\n",
       "      <th>LU2</th>\n",
       "      <th>LC2</th>\n",
       "      <th>LU1</th>\n",
       "      <th>LC1</th>\n",
       "      <th>nbr1_LU3</th>\n",
       "      <th>nbr1_LC3</th>\n",
       "      <th>...</th>\n",
       "      <th>nbr7_LC2</th>\n",
       "      <th>nbr7_LU1</th>\n",
       "      <th>nbr7_LC1</th>\n",
       "      <th>nbr8_LU3</th>\n",
       "      <th>nbr8_LC3</th>\n",
       "      <th>nbr8_LU2</th>\n",
       "      <th>nbr8_LC2</th>\n",
       "      <th>nbr8_LU1</th>\n",
       "      <th>nbr8_LC1</th>\n",
       "      <th>changed</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RELI</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48561099</th>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>...</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU221</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>LU301</td>\n",
       "      <td>LC41</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48611112</th>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>...</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU221</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU221</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU221</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU221</td>\n",
       "      <td>LC21</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48621113</th>\n",
       "      <td>LU103</td>\n",
       "      <td>LC47</td>\n",
       "      <td>LU103</td>\n",
       "      <td>LC47</td>\n",
       "      <td>LU421</td>\n",
       "      <td>LC31</td>\n",
       "      <td>LU421</td>\n",
       "      <td>LC31</td>\n",
       "      <td>LU106</td>\n",
       "      <td>LC12</td>\n",
       "      <td>...</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU222</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48621114</th>\n",
       "      <td>LU106</td>\n",
       "      <td>LC12</td>\n",
       "      <td>LU106</td>\n",
       "      <td>LC12</td>\n",
       "      <td>LU106</td>\n",
       "      <td>LC12</td>\n",
       "      <td>LU106</td>\n",
       "      <td>LC12</td>\n",
       "      <td>LU142</td>\n",
       "      <td>LC15</td>\n",
       "      <td>...</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU222</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48621115</th>\n",
       "      <td>LU142</td>\n",
       "      <td>LC11</td>\n",
       "      <td>LU142</td>\n",
       "      <td>LC15</td>\n",
       "      <td>LU142</td>\n",
       "      <td>LC15</td>\n",
       "      <td>LU142</td>\n",
       "      <td>LC15</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>...</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU222</td>\n",
       "      <td>LC21</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>LU402</td>\n",
       "      <td>LC61</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 57 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            LU4   LC4    LU3   LC3    LU2   LC2    LU1   LC1 nbr1_LU3  \\\n",
       "RELI                                                                    \n",
       "48561099  LU301  LC41  LU301  LC41  LU301  LC41  LU301  LC41    LU301   \n",
       "48611112  LU402  LC61  LU402  LC61  LU402  LC61  LU402  LC61    LU402   \n",
       "48621113  LU103  LC47  LU103  LC47  LU421  LC31  LU421  LC31    LU106   \n",
       "48621114  LU106  LC12  LU106  LC12  LU106  LC12  LU106  LC12    LU142   \n",
       "48621115  LU142  LC11  LU142  LC15  LU142  LC15  LU142  LC15    LU402   \n",
       "\n",
       "         nbr1_LC3  ... nbr7_LC2 nbr7_LU1 nbr7_LC1 nbr8_LU3 nbr8_LC3 nbr8_LU2  \\\n",
       "RELI               ...                                                         \n",
       "48561099     LC41  ...     LC21    LU221     LC21    LU301     LC41    LU301   \n",
       "48611112     LC61  ...     LC21    LU221     LC21    LU221     LC21    LU221   \n",
       "48621113     LC12  ...     LC21    LU222     LC21    LU402     LC61    LU402   \n",
       "48621114     LC15  ...     LC21    LU222     LC21    LU402     LC61    LU402   \n",
       "48621115     LC61  ...     LC21    LU222     LC21    LU402     LC61    LU402   \n",
       "\n",
       "         nbr8_LC2 nbr8_LU1 nbr8_LC1 changed  \n",
       "RELI                                         \n",
       "48561099     LC41    LU301     LC41       0  \n",
       "48611112     LC21    LU221     LC21       0  \n",
       "48621113     LC61    LU402     LC61       0  \n",
       "48621114     LC61    LU402     LC61       0  \n",
       "48621115     LC61    LU402     LC61       1  \n",
       "\n",
       "[5 rows x 57 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_features = original_data.copy()\n",
    "data_features['changed'] = [0 if row['LU4'] == row['LU3'] and row['LC4'] == row['LC3'] else 1 for ind, row in data_features[['LU4', 'LC4', 'LU3', 'LC3']].iterrows()]\n",
    "data_features.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4aba09aa-c44c-4d8d-b1ba-dabdeba7bef0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of tiles that changed label in either Land Cover or Land Usage: 58737\n"
     ]
    }
   ],
   "source": [
    "print('Total number of tiles that changed label in either Land Cover or Land Usage: %d' % sum(data_features.changed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f1bb02d-ae51-4fb9-a4a6-28007acc6694",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_set(data_to_split, ratio=0.8):\n",
    "    mask = np.random.rand(len(data_to_split)) < ratio\n",
    "    return [data_to_split[mask].reset_index(drop=True), data_to_split[~mask].reset_index(drop=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "be6cf6b6-92a0-4fb6-8a07-992756fea995",
   "metadata": {},
   "outputs": [],
   "source": [
    "[train, test] = split_set(data_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "96286028-a5f8-4579-8712-3fb9c0a56747",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['changed', 'LU4_LU101', 'LU4_LU102', 'LU4_LU103', 'LU4_LU104',\n",
       "       'LU4_LU105', 'LU4_LU106', 'LU4_LU107', 'LU4_LU108', 'LU4_LU121',\n",
       "       ...\n",
       "       'nbr8_LC1_LC45', 'nbr8_LC1_LC46', 'nbr8_LC1_LC47', 'nbr8_LC1_LC51',\n",
       "       'nbr8_LC1_LC52', 'nbr8_LC1_LC53', 'nbr8_LC1_LC61', 'nbr8_LC1_LC62',\n",
       "       'nbr8_LC1_LC63', 'nbr8_LC1_LC64'],\n",
       "      dtype='object', length=2045)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_categorical = pd.get_dummies(train)\n",
    "train_categorical.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7efc7634-0862-4f7b-9aa9-ead1dc0a5d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make sure we use only the features available in the training set\n",
    "test_categorical = pd.get_dummies(test)[train_categorical.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fa2715a0-9c51-420f-8265-1e5e130b493b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of the train dataset : 278767\n",
      "Length of the test dataset : 69707\n"
     ]
    }
   ],
   "source": [
    "train_label=train_categorical.changed\n",
    "train_features = train_categorical.drop('changed', axis=1)\n",
    "print('Length of the train dataset : {}'.format(len(train)))\n",
    "\n",
    "test_label=test_categorical.changed\n",
    "test_features = test_categorical.drop('changed', axis=1)\n",
    "print('Length of the test dataset : {}'.format(len(test)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6c7eab-199a-419f-a8c9-866a2c2b57d7",
   "metadata": {},
   "source": [
    "### B) Train a random forest classifier on your training set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "97e0f8b2-6cad-4d15-bac9-749479912a8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def compute_confusion_matrix(true_label, prediction_proba, decision_threshold=0.5, definition='normal'): \n",
    "    \n",
    "    assert definition == 'normal' or definition == 'special'\n",
    "    predict_label = (prediction_proba[:,1]>decision_threshold).astype(int)   \n",
    "    \n",
    "    if definition == 'normal':\n",
    "        # normal definition of confusion matrix \n",
    "        TP = np.sum(np.logical_and(predict_label==1, true_label==1))\n",
    "        TN = np.sum(np.logical_and(predict_label==0, true_label==0))\n",
    "        FP = np.sum(np.logical_and(predict_label==1, true_label==0))\n",
    "        FN = np.sum(np.logical_and(predict_label==0, true_label==1))\n",
    "    \n",
    "    elif definition == 'special':\n",
    "        # special definition of the confusion matrix in this case to optimize the recall and precision of unchanged\n",
    "        TP = np.sum(np.logical_and(predict_label==0, true_label==0))\n",
    "        TN = np.sum(np.logical_and(predict_label==1, true_label==1))\n",
    "        FP = np.sum(np.logical_and(predict_label==0, true_label==1))\n",
    "        FN = np.sum(np.logical_and(predict_label==1, true_label==0))\n",
    "    \n",
    "    confusion_matrix = np.asarray([[TP, FP],\n",
    "                                    [FN, TN]])\n",
    "    return confusion_matrix\n",
    "\n",
    "\n",
    "def plot_confusion_matrix(confusion_matrix, thred, axs):\n",
    "    [[TP, FP],[FN, TN]] = confusion_matrix\n",
    "    label = np.asarray([['TP {}'.format(TP), 'FP {}'.format(FP)],\n",
    "                        ['FN {}'.format(FN), 'TN {}'.format(TN)]])\n",
    "    \n",
    "    df_cm = pd.DataFrame(confusion_matrix, index=['Yes', 'No'], columns=['Positive', 'Negative']) \n",
    "    \n",
    "    sn.heatmap(df_cm, cmap='YlOrRd', annot=label, annot_kws={\"size\": 16}, cbar=False, fmt='',ax=axs)\n",
    "    axs.set_xlabel('Actual')\n",
    "    axs.set_ylabel('Predicted')\n",
    "    axs.set_title('Confusion matrix for a {} threshold'.format(thred))\n",
    "    \n",
    "\n",
    "\n",
    "def compute_all_score(confusion_matrix, t=0.5):\n",
    "    [[TP, FP],[FN, TN]] = confusion_matrix.astype(float)\n",
    "    \n",
    "    accuracy =  (TP+TN)/np.sum(confusion_matrix)\n",
    "    \n",
    "    precision_positive = TP/(TP+FP) if (TP+FP) !=0 else np.nan\n",
    "    precision_negative = TN/(TN+FN) if (TN+FN) !=0 else np.nan\n",
    "    \n",
    "    recall_positive = TP/(TP+FN) if (TP+FN) !=0 else np.nan\n",
    "    recall_negative = TN/(TN+FP) if (TN+FP) !=0 else np.nan\n",
    "\n",
    "    F1_score_positive = 2 *(precision_positive*recall_positive)/(precision_positive+recall_positive) if (precision_positive+recall_positive) !=0 else np.nan\n",
    "    F1_score_negative = 2 *(precision_negative*recall_negative)/(precision_negative+recall_negative) if (precision_negative+recall_negative) !=0 else np.nan\n",
    "\n",
    "    return [t, accuracy, precision_positive, recall_positive, F1_score_positive, precision_negative, recall_negative, F1_score_negative]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42611bbe-eef2-4a40-9257-39bdb055a193",
   "metadata": {},
   "source": [
    "Optimize the Random Forest Classifier with Optuna "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c9441d84-aea4-4c39-88ca-fc1979264901",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-16 10:28:41,452]\u001b[0m Using an existing study with name 'random_forest-study' instead of creating a new one.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using an existing study with name 'random_forest-study' instead of creating a new one.\n"
     ]
    }
   ],
   "source": [
    "def objective(trial):\n",
    "    '''\n",
    "    Execute optuna and set hyperparameters\n",
    "    '''\n",
    "    criterion = trial.suggest_categorical('criterion', [\"gini\", \"entropy\", \"log_loss\"])\n",
    "    bootstrap = trial.suggest_categorical('bootstrap',['True','False'])\n",
    "    max_depth = trial.suggest_int('max_depth', 1, 1000)\n",
    "    max_features = trial.suggest_categorical('max_features', [None, 'sqrt','log2'])\n",
    "    min_samples_split = trial.suggest_int('min_samples_split', 2, 10)\n",
    "    min_samples_leaf = trial.suggest_int('min_samples_leaf', 1, 10)\n",
    "    n_estimators =  trial.suggest_int('n_estimators', 100, 1000, 100)\n",
    "    \n",
    "    regr = RandomForestClassifier(bootstrap = bootstrap, criterion = criterion,\n",
    "                                  max_depth = max_depth, max_features = max_features,\n",
    "                                  n_estimators = n_estimators, min_samples_split = min_samples_split,\n",
    "                                  min_samples_leaf = min_samples_leaf, n_jobs=-1, class_weight = 'balanced_subsample')\n",
    "\n",
    "    \n",
    "    score = cross_val_score(regr, train_features, train_label, cv=5, scoring=\"balanced_accuracy\")\n",
    "    acc_mean = score.mean()\n",
    "\n",
    "    return acc_mean\n",
    "\n",
    "# Add stream handler of stdout to show the messages\n",
    "# optuna.logging.get_logger(\"optuna\").addHandler(logging.StreamHandler(sys.stdout))\n",
    "study_name = \"random_forest-study\" \n",
    "storage_name = \"sqlite:///{}.db\".format(study_name)\n",
    "\n",
    "study = optuna.create_study(study_name=study_name, direction='maximize', storage=storage_name, load_if_exists=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32135a8e-446c-4ef6-9959-2e4e07a0a8a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m[I 2022-09-16 10:47:26,785]\u001b[0m Trial 2 finished with value: 0.9276979739261162 and parameters: {'criterion': 'log_loss', 'bootstrap': 'False', 'max_depth': 695, 'max_features': 'sqrt', 'min_samples_split': 9, 'min_samples_leaf': 6, 'n_estimators': 500}. Best is trial 2 with value: 0.9276979739261162.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Trial 2 finished with value: 0.9276979739261162 and parameters: {'criterion': 'log_loss', 'bootstrap': 'False', 'max_depth': 695, 'max_features': 'sqrt', 'min_samples_split': 9, 'min_samples_leaf': 6, 'n_estimators': 500}. Best is trial 2 with value: 0.9276979739261162.\n"
     ]
    }
   ],
   "source": [
    "optuna.logging.enable_default_handler()\n",
    "study.optimize(objective, n_trials=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e5d06f8-d28b-41d3-ad24-26729907cb53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Create an instance with tuned hyperparameters\n",
    "optimised_rf = RandomForestClassifier(bootstrap = study.best_params['bootstrap'], criterion = study.best_params['criterion'],\n",
    "                                     max_depth = study.best_params['max_depth'], max_features = study.best_params['max_features'],\n",
    "                                     max_leaf_nodes = study.best_params['max_leaf_nodes'],n_estimators = study.best_params['n_estimators'],\n",
    "                                     n_jobs=2)\n",
    "#learn\n",
    "optimised_rf.fit(X_train ,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25859ae0-9a93-4e38-b826-99f32b2093fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    \n",
    "    regressor = trial.suggest_categorical('regressor', self._regressors)\n",
    "\n",
    "\n",
    "    # TODO: make sure we do not hit boundaries!\n",
    "\n",
    "    if regressor == 'RandomForest':\n",
    "\n",
    "\n",
    "        # cf. https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html\n",
    "\n",
    "        params = dict(\n",
    "\n",
    "            oob_score=False, \n",
    "\n",
    "            max_depth=trial.suggest_int('max_depth', 1, 50),\n",
    "\n",
    "            n_estimators=int(trial.suggest_discrete_uniform('n_estimators', 100, 1000, 100)),\n",
    "\n",
    "            min_samples_split=trial.suggest_int('min_samples_split', 2, 10),\n",
    "\n",
    "            min_samples_leaf=trial.suggest_int('min_samples_leaf', 1, 10),\n",
    "\n",
    "            max_features=trial.suggest_categorical('max_features', [None, \"sqrt\", \"log2\"])\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "        model = RandomForestRegressor(**params, n_jobs=1)\n",
    "\n",
    "\n",
    "    elif regressor == 'XGBoost':\n",
    "\n",
    "\n",
    "        # cf. https://xgboost.readthedocs.io/en/latest/python/python_api.html?highlight=n_estimators#module-xgboost.sklearn\n",
    "\n",
    "        params = dict(\n",
    "\n",
    "            booster=trial.suggest_categorical('booster', [\"gbtree\"]),\n",
    "\n",
    "            learning_rate=trial.suggest_uniform('learning_rate', 0, 1),\n",
    "\n",
    "            gamma=trial.suggest_uniform('gamma', 0, 10),\n",
    "\n",
    "            max_depth=trial.suggest_int('max_depth', 1, 50),\n",
    "\n",
    "            n_estimators=int(trial.suggest_discrete_uniform('n_estimators', 100, 1000, 100))\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "        model = XGBRegressor(**params, n_jobs=1, importance_type='gain')\n",
    "\n",
    "\n",
    "    elif regressor == 'LightGBM':\n",
    "\n",
    "\n",
    "        # cf. https://lightgbm.readthedocs.io/en/latest/pythonapi/lightgbm.LGBMRegressor.html\n",
    "\n",
    "        params = dict(  \n",
    "\n",
    "            learning_rate=trial.suggest_uniform('learning_rate', 0, 1),\n",
    "\n",
    "            num_leaves=trial.suggest_int('num_leaves', 2, 50),\n",
    "\n",
    "            max_depth=trial.suggest_int('max_depth', 1, 50),\n",
    "\n",
    "            n_estimators=int(trial.suggest_discrete_uniform('n_estimators', 100, 1000, 100)),\n",
    "\n",
    "            min_child_samples=trial.suggest_int('min_child_samples', 1, 10)\n",
    "\n",
    "        )\n",
    "\n",
    "\n",
    "        model = LGBMRegressor(**params, n_jobs=1, importance_type='gain')\n",
    "\n",
    "\n",
    "    else:\n",
    "\n",
    "\n",
    "        raise Exception('Invalid regressor. Only the following choices are valid: \"RandomForest\", \"XGBoost\", \"LightGBM\".')\n",
    "\n",
    "\n",
    "    score = cross_val_score(model, trn_X, trn_y, n_jobs=max(self.n_cpus//2, 1), cv=cv)\n",
    "\n",
    "    accuracy = score.min()\n",
    "\n",
    "\n",
    "    return accuracy\n",
    "\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction='maximize')\n",
    "\n",
    "study.optimize(objective, n_trials=n_trials, n_jobs=max(self.n_cpus//2, 1))\n",
    "\n",
    "\n",
    "# /!\\ we need to make sure that type(n_estimators) == 'int'\n",
    "\n",
    "best_params = study.best_params.copy()\n",
    "\n",
    "best_params['n_estimators'] = int(best_params['n_estimators'])\n",
    "\n",
    "\n",
    "print(\"Best parameters:\", best_params)\n",
    "\n",
    "print(f\"Best score (minimum R2-score after {cv}-fold Cross Validation):\", study.best_value)\n",
    "\n",
    "\n",
    "# best_model = RandomForestRegressor(**best_params)\n",
    "\n",
    "# best_model.fit(trn_X, trn_y)\n",
    "\n",
    "\n",
    "# metrics = self._evaluate(best_model, trn_X, trn_y, tst_X, tst_y)\n",
    "\n",
    "# print(\"Best model metrics:\", json.dumps(metrics, indent=4))\n",
    "\n",
    "\n",
    "self._best_params = study.best_params\n",
    "\n",
    "\n",
    "return best_params"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:landstats] *",
   "language": "python",
   "name": "conda-env-landstats-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
